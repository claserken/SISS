{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claserken/mambaforge/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/claserken/Developer/dataunlearning/metrics/song_likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diffusion_pytorch_model.safetensors not found\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"google/ddpm-celebahq-256\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load model and scheduler\n",
    "ddpm = DDPMPipeline.from_pretrained(model_id).to(device)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    return image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = load_image('../data/examples/celeba_hq_256/10000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ddpm.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sde_lib\n",
    "from likelihood import get_likelihood_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPMScheduler {\n",
       "  \"_class_name\": \"DDPMScheduler\",\n",
       "  \"_diffusers_version\": \"0.27.2\",\n",
       "  \"beta_end\": 0.02,\n",
       "  \"beta_schedule\": \"linear\",\n",
       "  \"beta_start\": 0.0001,\n",
       "  \"clip_sample\": true,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"steps_offset\": 0,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null,\n",
       "  \"variance_type\": \"fixed_small\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler # matches default VPSDE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde = sde_lib.VPSDE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_fn = get_likelihood_fn(sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "model = UNet2DModel.from_pretrained('/home/claserken/Developer/dataunlearning/checkpoints/celeb/deletion/2024-08-30_04-04-45/checkpoint-20/unet').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = likelihood_fn(model, torch.randn(1, 3, 256, 256, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9.1719], device='cuda:0'),\n",
       " tensor([[[[-1.9878, -0.1042,  0.2928,  ..., -0.6378, -0.5451, -0.1143],\n",
       "           [-0.0117, -0.2000,  0.2598,  ..., -1.2336, -0.0825, -1.0213],\n",
       "           [ 0.4781,  0.7857,  0.8542,  ...,  2.1790,  2.5461,  0.3577],\n",
       "           ...,\n",
       "           [-0.9474, -1.2104,  0.9481,  ..., -0.1677, -1.3332,  0.4809],\n",
       "           [-0.1778, -0.4073, -2.5542,  ..., -1.0388,  1.2164,  0.4333],\n",
       "           [-1.0357,  1.7204, -2.4044,  ...,  0.3515, -0.1471, -1.4446]],\n",
       " \n",
       "          [[-0.8550, -0.4344,  0.9014,  ..., -0.2972,  0.1901,  0.2502],\n",
       "           [-2.1319,  0.7314,  0.4469,  ..., -0.1239, -0.1865, -0.1318],\n",
       "           [-0.6346,  1.5013,  0.3284,  ..., -0.6705, -0.9352,  0.7832],\n",
       "           ...,\n",
       "           [ 1.3237, -1.3118, -0.1264,  ...,  0.5369, -0.1172, -0.7119],\n",
       "           [ 0.5856, -0.1026,  0.7952,  ...,  0.8756,  0.1312,  0.7500],\n",
       "           [-2.0602, -0.4493,  1.8116,  ..., -0.3420, -0.8863,  0.1094]],\n",
       " \n",
       "          [[ 1.5364, -0.9941,  0.7757,  ..., -0.5067,  0.6786,  0.2638],\n",
       "           [ 1.7549,  0.5151, -0.7995,  ...,  0.8605,  2.0686, -1.6602],\n",
       "           [-0.2572, -1.7137, -0.7753,  ..., -0.6700, -0.1603,  0.1710],\n",
       "           ...,\n",
       "           [-1.6446,  1.1372, -1.9389,  ..., -0.1294,  2.6973,  0.2300],\n",
       "           [ 1.2221,  1.1119,  0.6177,  ..., -0.7869,  0.2499, -0.6001],\n",
       "           [-0.2958, -0.2351,  0.5951,  ...,  0.6088, -1.3073,  2.0445]]]],\n",
       "        device='cuda:0'),\n",
       " 356)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = likelihood_fn(model, train_img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.2540], device='cuda:0'),\n",
       " tensor([[[[-1.2867, -0.8036, -0.8242,  ..., -0.5800,  0.4676, -0.0913],\n",
       "           [ 0.3851,  1.2567,  1.0880,  ...,  1.2021,  1.1049,  1.5980],\n",
       "           [-0.1945,  0.3565,  0.0395,  ...,  0.5469,  0.7246,  1.6694],\n",
       "           ...,\n",
       "           [ 0.5186,  0.8699,  0.4212,  ...,  0.1673,  0.9407, -0.5756],\n",
       "           [-0.0361,  0.1206,  0.0865,  ...,  0.0918,  1.4830,  0.9634],\n",
       "           [-1.5456, -0.5031, -0.0382,  ..., -0.4738, -0.2906,  0.5479]],\n",
       " \n",
       "          [[-0.3052,  0.6698,  1.3276,  ...,  0.0816, -0.0766, -1.0778],\n",
       "           [ 0.6772,  1.4056,  1.4685,  ...,  0.7519,  1.0482, -0.5629],\n",
       "           [ 0.3534,  1.1467,  0.9835,  ...,  0.4097,  0.8647, -0.1984],\n",
       "           ...,\n",
       "           [ 0.3395,  0.8517,  0.5164,  ..., -0.7547, -2.2606, -0.4302],\n",
       "           [-0.5895, -0.0075, -0.0501,  ...,  0.4433, -0.3146,  0.5051],\n",
       "           [-0.7600,  0.7295,  0.9603,  ...,  0.7245,  1.0796, -0.0232]],\n",
       " \n",
       "          [[ 0.1133, -0.4922,  0.5320,  ..., -0.2581,  0.1967,  0.0436],\n",
       "           [ 0.0765,  1.3252,  1.9226,  ...,  0.6828,  0.8302,  1.1745],\n",
       "           [ 0.1694,  0.9480,  1.6078,  ...,  0.2746,  0.7251,  0.7871],\n",
       "           ...,\n",
       "           [ 0.2114,  1.6326,  1.4923,  ..., -0.1245, -0.9091, -3.3681],\n",
       "           [-0.4937,  0.9429,  1.1413,  ..., -1.3676,  2.0240, -1.5495],\n",
       "           [-1.3841,  0.3215,  0.6473,  ...,  0.8976,  0.2393,  2.9218]]]],\n",
       "        device='cuda:0'),\n",
       " 566)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
