{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSCD_MODEL_PATH = \"/home/ubuntu/Developer/dataunlearning/checkpoints/classifiers/sscd_disc_mixup.torchscript.pt\"\n",
    "model = torch.jit.load(SSCD_MODEL_PATH).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],\n",
    ")\n",
    "sscd_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '/home/ubuntu/Developer/dataunlearning/data/examples/manual/stallone/images'\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_000.png', 'image_001.png', 'image_002.png', 'image_003.png', 'image_004.png', 'image_005.png', 'image_006.png', 'image_007.png', 'image_008.png', 'image_009.png', 'image_010.png', 'image_011.png', 'image_012.png', 'image_013.png', 'image_014.png', 'image_015.png', 'image_016.png', 'image_017.png', 'image_018.png', 'image_019.png', 'image_020.png', 'image_021.png', 'image_022.png', 'image_023.png', 'image_024.png', 'image_025.png', 'image_026.png', 'image_027.png', 'image_028.png', 'image_029.png', 'image_030.png', 'image_031.png', 'image_032.png', 'image_033.png', 'image_034.png', 'image_035.png', 'image_036.png', 'image_037.png', 'image_038.png', 'image_039.png', 'image_040.png', 'image_041.png', 'image_042.png', 'image_043.png', 'image_044.png', 'image_045.png', 'image_046.png', 'image_047.png', 'image_048.png', 'image_049.png', 'image_050.png', 'image_051.png', 'image_052.png', 'image_053.png', 'image_054.png', 'image_055.png', 'image_056.png', 'image_057.png', 'image_058.png', 'image_059.png', 'image_060.png', 'image_061.png', 'image_062.png', 'image_063.png', 'image_064.png', 'image_065.png', 'image_066.png', 'image_067.png', 'image_068.png', 'image_069.png', 'image_070.png', 'image_071.png', 'image_072.png', 'image_073.png', 'image_074.png', 'image_075.png', 'image_076.png', 'image_077.png', 'image_078.png', 'image_079.png', 'image_080.png', 'image_081.png', 'image_082.png', 'image_083.png', 'image_084.png', 'image_085.png', 'image_086.png', 'image_087.png', 'image_088.png', 'image_089.png', 'image_090.png', 'image_091.png', 'image_092.png', 'image_093.png', 'image_094.png', 'image_095.png', 'image_096.png', 'image_097.png', 'image_098.png', 'image_099.png']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sscd_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_DIR, image_file)\n\u001b[1;32m     13\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     batch_images\u001b[38;5;241m.\u001b[39mappend(\u001b[43msscd_transform\u001b[49m(img))\n\u001b[1;32m     16\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batch_images)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m model(batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sscd_transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and compute embeddings for all images in batches\n",
    "embeddings = []\n",
    "image_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.endswith(\".png\")])\n",
    "print(image_files)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(image_files), BATCH_SIZE):\n",
    "        batch_files = image_files[i:i+BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        \n",
    "        for image_file in batch_files:\n",
    "            image_path = os.path.join(IMAGE_DIR, image_file)\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            batch_images.append(sscd_transform(img))\n",
    "        \n",
    "        batch = torch.stack(batch_images).to('cuda')\n",
    "        batch_embeddings = model(batch)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities for a given index\n",
    "index = 6  # Change this to the desired index\n",
    "query_embedding = embeddings[index]\n",
    "\n",
    "similarities = torch.matmul(query_embedding, embeddings.T).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0686,  0.1157,  0.4641,  0.4284,  0.1390,  0.3418,  1.0000,  0.1676,\n",
      "         0.1097,  0.4163,  0.0440,  0.2360,  0.5935,  0.0961,  0.4086,  0.0315,\n",
      "         0.6302,  0.1257,  0.0184,  0.5222,  0.2936,  0.1716,  0.6055,  0.2554,\n",
      "         0.2349,  0.2602,  0.4827,  0.3334,  0.0658,  0.6232, -0.0026,  0.1347,\n",
      "         0.4415,  0.0995,  0.6586,  0.0440,  0.5676,  0.4527,  0.4695,  0.1406,\n",
      "         0.1409,  0.1063,  0.1117,  0.1961,  0.6566,  0.4685,  0.4433,  0.2017,\n",
      "         0.0912,  0.2524,  0.3964,  0.3502,  0.2420,  0.1105,  0.0517,  0.2889,\n",
      "         0.2310,  0.4873,  0.0423,  0.4430,  0.4850,  0.2552,  0.2722,  0.4578,\n",
      "         0.0464,  0.2186,  0.5384,  0.5274,  0.6258,  0.5908,  0.0258,  0.0760,\n",
      "         0.3305,  0.1807,  0.5153,  0.4224,  0.5664,  0.5899,  0.0291,  0.5845,\n",
      "         0.2894,  0.0987,  0.0557,  0.2318,  0.5865,  0.1614,  0.0010,  0.6636,\n",
      "         0.4240,  0.5979,  0.7028,  0.0158,  0.2090,  0.1725,  0.6484,  0.1859,\n",
      "         0.4413,  0.0011,  0.5301,  0.1951], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with similarity above 0.4 to index 6:\n",
      "- image_002.png\n",
      "- image_003.png\n",
      "- image_006.png\n",
      "- image_009.png\n",
      "- image_012.png\n",
      "- image_014.png\n",
      "- image_016.png\n",
      "- image_019.png\n",
      "- image_022.png\n",
      "- image_026.png\n",
      "- image_029.png\n",
      "- image_032.png\n",
      "- image_034.png\n",
      "- image_036.png\n",
      "- image_037.png\n",
      "- image_038.png\n",
      "- image_044.png\n",
      "- image_045.png\n",
      "- image_046.png\n",
      "- image_057.png\n",
      "- image_059.png\n",
      "- image_060.png\n",
      "- image_063.png\n",
      "- image_066.png\n",
      "- image_067.png\n",
      "- image_068.png\n",
      "- image_069.png\n",
      "- image_074.png\n",
      "- image_075.png\n",
      "- image_076.png\n",
      "- image_077.png\n",
      "- image_079.png\n",
      "- image_084.png\n",
      "- image_087.png\n",
      "- image_088.png\n",
      "- image_089.png\n",
      "- image_090.png\n",
      "- image_094.png\n",
      "- image_096.png\n",
      "- image_098.png\n"
     ]
    }
   ],
   "source": [
    "# Find images with similarity above 0.7\n",
    "threshold = 0.4\n",
    "similar_indices = torch.where(similarities > threshold)[0].tolist()\n",
    "\n",
    "print(f\"Images with similarity above {threshold} to index {index}:\")\n",
    "for i in similar_indices:\n",
    "    print(f\"- {image_files[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
