defaults:
  - base_cifar
  - _self_

task:
  _target_: delete_unconditional.DeleteUnconditional

project_name: cifar-deletion-hf
output_dir: checkpoints/cifar/deletion
checkpoint_path: checkpoints/cifar/base/retrain/checkpoint-550000 # checkpoints/cifar/base/final/checkpoint-550000 # google/ddpm-cifar10-32 # checkpoints/cifar/base/2024-04-17_03-08-11/checkpoint-60000 #checkpoints/cifar/base/pretrained/ddpm_ema_cifar10

deletion:
  class_label: 1 # class to remove
  frac_deletion: 0.1 # each class is 10% of dataset
  loss_fn: importance_sampling_with_mixture # Options are [importance_sampling_with_mixture, double_forward_with_neg_del, naive_del, simple_neg_del, modified_noise_obj]
  timestep_del_window: null # only for modified_noise_obj (500 is good)
  loss_params: {}
    # superfactor: 2.5
    # lambd: 0.5
  superfactor_decay: null
  # IGNORE ALL BELOW: just placeholders for running sweep
  inception_frequency: null 
  training_steps: null

metrics:
  classifier_cfg:
    _target_: metrics.classifier.Classifier
    # classifier:
    #   _target_: metrics.cifar_resnet.resnet56
    classifier:
      _target_: hydra.utils.get_object
      path: torch.hub.load
    classifier_ckpt: null
    classifier_args: 
      repo_or_dir: chenyaofo/pytorch-cifar-models
      model: cifar10_resnet32
      pretrained: true
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.Normalize # CIFAR normalizationf from (https://github.com/chenyaofo/image-classification-codebase/blob/master/conf/cifar10.conf)
          mean: [0.4914, 0.4822, 0.4465]
          std: [0.2023, 0.1994, 0.2010]
  fraction_deletion: false
  inception_score: null
    # class_cfg: 
    #   _target_: metrics.inception_score.InceptionScore
    #   remove_class: ${deletion.class_label}
    # step_frequency: 1
    # num_imgs_to_generate: 16384
    # batch_size: 2048
  fid: # null
    class_cfg:
      _target_: metrics.fid.FIDEvaluator
      remove_class: ${deletion.class_label}
      filter_fake: false
      inception_batch_size: 256
    step_frequency: 1
    num_imgs_to_generate: 49152 #16384
    batch_size: 1024 # 4096
  membership_loss: null
    # class_cfg:
    #   _target_: metrics.class_membership.MembershipLoss
    #   num_image_samples: 64 #1024
    #   num_noise_samples: 64 #128
    #   eval_batch_size: 4096
    # timesteps: [200, 400, 600, 800, 900]
    # plot_params: null
    # #   save_path: 'cifar_losses.png'
    # #   time_frequency: 10 # initial graph for all membership losses
    # step_frequency: 1 # re-evaluate every gradient step

ema:
  use_ema: false # Unnecessary for deletion fine-tuning (only need to load in ema weights from training at start)

sampling_steps: 1 # Specifies number of gradient steps after which to evaluate
checkpointing_steps: 50 # Specifies number of gradient steps after which to save checkpoint
training_steps: 300
warmup_steps: 0 # for lr scheduler
eval_batch_size: 144

dataset_all:
  _target_: data.src.hf_dataset.HFDataset
  filter: nondeletion
  name: ${dataset.name}
  split: ${dataset.split}
  class_to_remove: ${deletion.class_label}
  image_key: ${dataset.image_key}

dataset_deletion:
  _target_: data.src.hf_dataset.HFDataset
  filter: deletion
  name: ${dataset.name}
  split: ${dataset.split}
  class_to_remove: ${deletion.class_label}
  image_key: ${dataset.image_key}

optimizer:
  lr: 1e-5